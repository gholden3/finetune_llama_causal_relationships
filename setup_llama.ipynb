{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up llama includes the following steps:\n",
    "1. Connecting to the greene cluster\n",
    "2. Creating singularity and installing required packages\n",
    "3. Git clone the llama repository\n",
    "4. Asking for a compute node\n",
    "5. Running the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Logging in to Greene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Use NYU VPN (ignore it if you are on campus) and directly ssh to Greene\n",
    "2. `ssh netid@greene.hpc.nyu.edu`\n",
    "3. provide password\n",
    "```\n",
    "| \\ | \\ \\ / / | | | | | | |  _ \\ / ___|\n",
    "|  \\| |\\ V /| | | | | |_| | |_) | |\n",
    "| |\\  | | | | |_| | |  _  |  __/| |___\n",
    "|_| \\_| |_|  \\___/  |_| |_|_|    \\____|\n",
    "\n",
    "  ____\n",
    " / ___|_ __ ___  ___ _ __   ___\n",
    "| |  _| '__/ _ \\/ _ \\ '_ \\ / _ \\\n",
    "| |_| | | |  __/  __/ | | |  __/\n",
    " \\____|_|  \\___|\\___|_| |_|\\___|\n",
    " ```\n",
    " `[yb970@log-2 ~]$ `\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Setting up the environment\n",
    "Setting up singularity according to https://sites.google.com/nyu.edu/nyu-hpc/hpc-systems/greene/software/singularity-with-miniconda <br>\n",
    "*For replication purpose, lets all use `/scratch/work/public/overlay-fs-ext3/overlay-25GB-500K.ext3.gz`*\n",
    "And we now have a conda environment that we can activate when we have requested a compute node and are ready to run our code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Get llama repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Generate a key pair on greene, and add it to your github account <br>\n",
    "https://docs.github.com/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent\n",
    "2. Change the directory to scratch in order to have enough space for the code <br>\n",
    "`cd /scratch/yb970/`\n",
    "3. Clone the llama repository <br>\n",
    "`git clone git@github.com:facebookresearch/llama.git`\n",
    "4. Change the directory to llama <br>\n",
    "`cd llama`\n",
    "5. Ask for a compute node (be sure to ask for large memory, otherwise the llama can not run)<br>\n",
    "`srun --pty -c 2 --mem=25GB --gres=gpu:v100:1 /bin/bash`\n",
    "6. Activate the conda environment (Replace the path with your own path (the overlay is what you have used in step 2)) <br>\n",
    "```\n",
    "singularity exec --bind /scratch --nv --overlay /scratch/yb970/capstone/overlay-25GB-500K.ext3:rw \\\n",
    "/scratch/work/public/singularity/cuda11.7.99-cudnn8.5-devel-ubuntu22.04.2.sif /bin/bash\n",
    "\n",
    "source /ext3/env.sh\n",
    "\n",
    "conda activate\n",
    "```\n",
    "6. Install llama according to https://github.com/facebookresearch/llama <br>\n",
    "`pip install -e .` <br>\n",
    "`bash download.sh` <br>\n",
    "It will prompt you to enter the URL you get from your email that grants you the access (Note that the URL expires in 24h. If it does, you should fill the form again and request a new one).\n",
    "7. Test that it is successfully installed <br>\n",
    "```\n",
    "torchrun --nproc_per_node 1 example_chat_completion.py \\\n",
    "--ckpt_dir llama-2-7b/ \\\n",
    "--tokenizer_path tokenizer.model \\\n",
    "--max_seq_len 512 --max_batch_size 6\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
